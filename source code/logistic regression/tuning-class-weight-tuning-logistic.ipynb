{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0975a132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:24.732543Z",
     "iopub.status.busy": "2022-07-21T11:54:24.731579Z",
     "iopub.status.idle": "2022-07-21T11:54:27.402626Z",
     "shell.execute_reply": "2022-07-21T11:54:27.401550Z"
    },
    "papermill": {
     "duration": 2.683638,
     "end_time": "2022-07-21T11:54:27.405705",
     "exception": false,
     "start_time": "2022-07-21T11:54:24.722067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV, train_test_split, RepeatedStratifiedKFold, cross_val_score, learning_curve\n",
    "from sklearn.metrics import classification_report, fbeta_score, confusion_matrix, precision_recall_curve, auc, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf3ac12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:27.421746Z",
     "iopub.status.busy": "2022-07-21T11:54:27.420736Z",
     "iopub.status.idle": "2022-07-21T11:54:39.727956Z",
     "shell.execute_reply": "2022-07-21T11:54:39.726632Z"
    },
    "papermill": {
     "duration": 12.318073,
     "end_time": "2022-07-21T11:54:39.730719",
     "exception": false,
     "start_time": "2022-07-21T11:54:27.412646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accepted_loans = pd.read_csv('../input/elitedata/elite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bada1e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:39.746119Z",
     "iopub.status.busy": "2022-07-21T11:54:39.745704Z",
     "iopub.status.idle": "2022-07-21T11:54:40.257300Z",
     "shell.execute_reply": "2022-07-21T11:54:40.256180Z"
    },
    "papermill": {
     "duration": 0.522667,
     "end_time": "2022-07-21T11:54:40.260103",
     "exception": false,
     "start_time": "2022-07-21T11:54:39.737436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = accepted_loans.loc[:, accepted_loans.columns != 'loan_paid'].values\n",
    "y = accepted_loans['loan_paid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7886a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:40.275458Z",
     "iopub.status.busy": "2022-07-21T11:54:40.274446Z",
     "iopub.status.idle": "2022-07-21T11:54:42.172726Z",
     "shell.execute_reply": "2022-07-21T11:54:42.171486Z"
    },
    "papermill": {
     "duration": 1.908917,
     "end_time": "2022-07-21T11:54:42.175602",
     "exception": false,
     "start_time": "2022-07-21T11:54:40.266685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8efe572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.190871Z",
     "iopub.status.busy": "2022-07-21T11:54:42.190150Z",
     "iopub.status.idle": "2022-07-21T11:54:42.195298Z",
     "shell.execute_reply": "2022-07-21T11:54:42.194296Z"
    },
    "papermill": {
     "duration": 0.015265,
     "end_time": "2022-07-21T11:54:42.197626",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.182361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf8fe829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.212959Z",
     "iopub.status.busy": "2022-07-21T11:54:42.211954Z",
     "iopub.status.idle": "2022-07-21T11:54:42.216846Z",
     "shell.execute_reply": "2022-07-21T11:54:42.215707Z"
    },
    "papermill": {
     "duration": 0.015541,
     "end_time": "2022-07-21T11:54:42.219749",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.204208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "minmax_scaler = ('minmax', MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8bfa02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.235824Z",
     "iopub.status.busy": "2022-07-21T11:54:42.235054Z",
     "iopub.status.idle": "2022-07-21T11:54:42.240834Z",
     "shell.execute_reply": "2022-07-21T11:54:42.239957Z"
    },
    "papermill": {
     "duration": 0.016958,
     "end_time": "2022-07-21T11:54:42.243360",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.226402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_weights = [3.2, 3.6, 4.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a9bde2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.259062Z",
     "iopub.status.busy": "2022-07-21T11:54:42.258234Z",
     "iopub.status.idle": "2022-07-21T11:54:42.265457Z",
     "shell.execute_reply": "2022-07-21T11:54:42.264538Z"
    },
    "papermill": {
     "duration": 0.018275,
     "end_time": "2022-07-21T11:54:42.268216",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.249941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = ('lr', LogisticRegression())\n",
    "lr_param_grid = {\n",
    "    'lr__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__max_iter': [100, 500, 1000],\n",
    "    'lr__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'lr__class_weight': [{0: x, 1: 1.0} for x in class_weights]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096664c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.284017Z",
     "iopub.status.busy": "2022-07-21T11:54:42.283196Z",
     "iopub.status.idle": "2022-07-21T11:54:42.288231Z",
     "shell.execute_reply": "2022-07-21T11:54:42.287474Z"
    },
    "papermill": {
     "duration": 0.016087,
     "end_time": "2022-07-21T11:54:42.290971",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.274884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Metric\n",
    "f_onehalf_scorer = make_scorer(fbeta_score, beta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6a816e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.307138Z",
     "iopub.status.busy": "2022-07-21T11:54:42.306319Z",
     "iopub.status.idle": "2022-07-21T11:54:42.325303Z",
     "shell.execute_reply": "2022-07-21T11:54:42.324478Z"
    },
    "papermill": {
     "duration": 0.029854,
     "end_time": "2022-07-21T11:54:42.327818",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.297964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(\n",
    "    estimator,\n",
    "    title,\n",
    "    X,\n",
    "    y,\n",
    "    axes=None,\n",
    "    ylim=None,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "):\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(3, 1, figsize=(15, 15))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes,\n",
    "        scoring=f_onehalf_scorer,\n",
    "        return_times=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
    "    )\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, \"o-\")\n",
    "    axes[1].fill_between(\n",
    "        train_sizes,\n",
    "        fit_times_mean - fit_times_std,\n",
    "        fit_times_mean + fit_times_std,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    fit_time_argsort = fit_times_mean.argsort()\n",
    "    fit_time_sorted = fit_times_mean[fit_time_argsort]\n",
    "    test_scores_mean_sorted = test_scores_mean[fit_time_argsort]\n",
    "    test_scores_std_sorted = test_scores_std[fit_time_argsort]\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_time_sorted, test_scores_mean_sorted, \"o-\")\n",
    "    axes[2].fill_between(\n",
    "        fit_time_sorted,\n",
    "        test_scores_mean_sorted - test_scores_std_sorted,\n",
    "        test_scores_mean_sorted + test_scores_std_sorted,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[2].set_xlabel(\"fit_times\") \n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d57efae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.343287Z",
     "iopub.status.busy": "2022-07-21T11:54:42.342548Z",
     "iopub.status.idle": "2022-07-21T11:54:42.357748Z",
     "shell.execute_reply": "2022-07-21T11:54:42.356598Z"
    },
    "papermill": {
     "duration": 0.025948,
     "end_time": "2022-07-21T11:54:42.360250",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.334302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_search_results(search):\n",
    "    df = pd.DataFrame(search.cv_results_)\n",
    "    results = ['mean_test_score',\n",
    "            'mean_train_score',\n",
    "            'std_test_score', \n",
    "            'std_train_score']\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(param_grid), \n",
    "                          figsize = (7*len(param_grid), 5),\n",
    "                          sharey='row')\n",
    "    if len(param_grid) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    axes[0].set_ylabel(\"Score\", fontsize=25)\n",
    "\n",
    "\n",
    "    for idx, (param_name, param_range) in enumerate(param_grid.items()):\n",
    "        try:\n",
    "            grouped_df = df.groupby(f'param_{param_name}')[results]\\\n",
    "              .agg({'mean_train_score': 'mean',\n",
    "                    'mean_test_score': 'mean',\n",
    "                    'std_train_score': 'mean',\n",
    "                    'std_test_score': 'mean'})\n",
    "\n",
    "            previous_group = df.groupby(f'param_{param_name}')[results]\n",
    "            axes[idx].set_xlabel(param_name, fontsize=30)\n",
    "            axes[idx].set_ylim(0.0, 1.1)\n",
    "            lw = 2\n",
    "            axes[idx].plot(param_range, grouped_df['mean_train_score'], label=\"Training score\",\n",
    "                      color=\"darkorange\", lw=lw)\n",
    "            axes[idx].fill_between(param_range,grouped_df['mean_train_score'] - grouped_df['std_train_score'],\n",
    "                          grouped_df['mean_train_score'] + grouped_df['std_train_score'], alpha=0.2,\n",
    "                          color=\"darkorange\", lw=lw)\n",
    "            axes[idx].plot(param_range, grouped_df['mean_test_score'], label=\"Cross-validation score\",\n",
    "                      color=\"navy\", lw=lw)\n",
    "            axes[idx].fill_between(param_range, grouped_df['mean_test_score'] - grouped_df['std_test_score'],\n",
    "                          grouped_df['mean_test_score'] + grouped_df['std_test_score'], alpha=0.2,\n",
    "                          color=\"navy\", lw=lw)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.suptitle('Validation curves', fontsize=40)\n",
    "    fig.legend(handles, labels, loc=8, ncol=2, fontsize=20)\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.25, top=0.85)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f97fa56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.375113Z",
     "iopub.status.busy": "2022-07-21T11:54:42.374753Z",
     "iopub.status.idle": "2022-07-21T11:54:42.380997Z",
     "shell.execute_reply": "2022-07-21T11:54:42.379614Z"
    },
    "papermill": {
     "duration": 0.01678,
     "end_time": "2022-07-21T11:54:42.383548",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.366768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_result_df(search):\n",
    "  keeping_columns = ['params', 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score', 'mean_fit_time', 'std_fit_time']\n",
    "  df = pd.DataFrame(search.cv_results_)\n",
    "  df = df[keeping_columns].sort_values(by='mean_test_score', ascending=False)\n",
    "  return df.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29019ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.398835Z",
     "iopub.status.busy": "2022-07-21T11:54:42.398458Z",
     "iopub.status.idle": "2022-07-21T11:54:42.409273Z",
     "shell.execute_reply": "2022-07-21T11:54:42.408353Z"
    },
    "papermill": {
     "duration": 0.021117,
     "end_time": "2022-07-21T11:54:42.411425",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.390308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_best_model_result(search, name):\n",
    "  print(\"Best parameter (CV score=):\" % search.best_score_)\n",
    "  best_model = search.best_estimator_\n",
    "  print(best_model)\n",
    "\n",
    "  y_pred = best_model.predict(X_test)\n",
    "\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "  \n",
    "  f_onehalf_score = fbeta_score(y_test, y_pred, beta=0.5)\n",
    "  print('f0.5_score=', f_onehalf_score)\n",
    "\n",
    "  try :\n",
    "    y_score = best_model.predict_proba(X_test)[:, 1]\n",
    "    # calculate precision and recall for each threshold\n",
    "    precision, recall, threshold = precision_recall_curve(y_test, y_score)\n",
    "    # calculate scores\n",
    "    pr_auc = auc(recall, precision)\n",
    "    print('pr_auc_score=', pr_auc)\n",
    "\n",
    "    # calculate the no skill line as the proportion of the positive class\n",
    "    no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "    # plot the no skill precision-recall curve\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    # plot the model precision-recall curve\n",
    "    plt.plot(recall, precision, marker='.', label=name)\n",
    "    plt.title(f'{name}(pr_auc={pr_auc})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5037738d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.426509Z",
     "iopub.status.busy": "2022-07-21T11:54:42.425795Z",
     "iopub.status.idle": "2022-07-21T11:54:42.431445Z",
     "shell.execute_reply": "2022-07-21T11:54:42.430232Z"
    },
    "papermill": {
     "duration": 0.01574,
     "end_time": "2022-07-21T11:54:42.433737",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.417997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[minmax_scaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bedd4d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.448544Z",
     "iopub.status.busy": "2022-07-21T11:54:42.448089Z",
     "iopub.status.idle": "2022-07-21T11:54:42.453107Z",
     "shell.execute_reply": "2022-07-21T11:54:42.451861Z"
    },
    "papermill": {
     "duration": 0.015097,
     "end_time": "2022-07-21T11:54:42.455414",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.440317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = lr_param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e9128f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.470612Z",
     "iopub.status.busy": "2022-07-21T11:54:42.470199Z",
     "iopub.status.idle": "2022-07-21T11:54:42.475924Z",
     "shell.execute_reply": "2022-07-21T11:54:42.474527Z"
    },
    "papermill": {
     "duration": 0.016547,
     "end_time": "2022-07-21T11:54:42.478690",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.462143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = HalvingGridSearchCV(pipe, param_grid, scoring=f_onehalf_scorer, cv=cv, verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ddf2fe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T11:54:42.494210Z",
     "iopub.status.busy": "2022-07-21T11:54:42.493808Z",
     "iopub.status.idle": "2022-07-21T15:43:22.016317Z",
     "shell.execute_reply": "2022-07-21T15:43:22.013441Z"
    },
    "papermill": {
     "duration": 13719.533749,
     "end_time": "2022-07-21T15:43:22.019665",
     "exception": false,
     "start_time": "2022-07-21T11:54:42.485916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 13267\n",
      "max_resources_: 1074704\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 225\n",
      "n_resources: 13267\n",
      "Fitting 10 folds for each of 225 candidates, totalling 2250 fits\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.897) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.901, test=0.901) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.888) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.890) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.893) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.896, test=0.903) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.903, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.909) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.897) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.901, test=0.901) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.888) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.890) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.893) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.897) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.896, test=0.903) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.903, test=0.908) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.909) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.899) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.903, test=0.897) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.901) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.897, test=0.890) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.901, test=0.890) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.891) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.896, test=0.898) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.897, test=0.903) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.904, test=0.908) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.903, test=0.909) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.898) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.897) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.901, test=0.901) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.888) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.890) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.893) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.896, test=0.903) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.903, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.909) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.899) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.897) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.901, test=0.901) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.888) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.890) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.893) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.897) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.896, test=0.903) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.903, test=0.908) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.909) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.899) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.897) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.901, test=0.901) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.888) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.890) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.893) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.896, test=0.903) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.903, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.909) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.897) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.901, test=0.901) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.888) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.890) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.893) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.897) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.896, test=0.903) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.903, test=0.908) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.909) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.899) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.903, test=0.897) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.901) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.897, test=0.890) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.901, test=0.890) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.891) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.896, test=0.898) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.897, test=0.903) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.904, test=0.908) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.903, test=0.909) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.898) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.897) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.901, test=0.901) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.888) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.890) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.893) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.896, test=0.903) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.903, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.909) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.897) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.901, test=0.901) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.888) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.890) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.893) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.897) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.896, test=0.903) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.903, test=0.908) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.909) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.899) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.897) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.901, test=0.901) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.888) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.890) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.893) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.896, test=0.903) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.903, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.909) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.897) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.901, test=0.901) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.888) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.890) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.893) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.897) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.896, test=0.903) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.903, test=0.908) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.909) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.899) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.903, test=0.897) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.901) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.897, test=0.890) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.901, test=0.890) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.891) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.896, test=0.898) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.897, test=0.903) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.904, test=0.908) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.903, test=0.909) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.898) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.897) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.901, test=0.901) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.888) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.890) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.893) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.896, test=0.903) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.903, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.909) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.897) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.901, test=0.901) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.888) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.890) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.893) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.897) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.896, test=0.903) total time=   0.4s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.903, test=0.908) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.909) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.899) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.899, test=0.896) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.895, test=0.892) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.891) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.901, test=0.889) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.896, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.905) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.899, test=0.895) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.899, test=0.896) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.899) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.895, test=0.892) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.891) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.901, test=0.889) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.896, test=0.897) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.898, test=0.906) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.908) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.908) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.899, test=0.895) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.899, test=0.897) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.899) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.896, test=0.890) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.891) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.901, test=0.887) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.897, test=0.895) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.898, test=0.904) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.902, test=0.906) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.902, test=0.905) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.899, test=0.895) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.899, test=0.896) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.895, test=0.892) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.891) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.901, test=0.889) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.896, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.906) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.899, test=0.895) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.899, test=0.896) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.899) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.895, test=0.892) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.891) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.901, test=0.889) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.896, test=0.898) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.898, test=0.905) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.908) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.908) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.899, test=0.895) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.899, test=0.896) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.895, test=0.892) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.891) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.901, test=0.889) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.896, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.905) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.899, test=0.895) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.899, test=0.896) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.899) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.895, test=0.892) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.891) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.901, test=0.889) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.896, test=0.897) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.898, test=0.906) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.908) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.908) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.899, test=0.895) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.899, test=0.897) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.899) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.896, test=0.890) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.891) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.901, test=0.887) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.897, test=0.895) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.898, test=0.904) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.902, test=0.906) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.902, test=0.905) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.899, test=0.895) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.899, test=0.896) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.895, test=0.892) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.891) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.901, test=0.889) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.896, test=0.898) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.905) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.899, test=0.895) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.899, test=0.896) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.899) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.895, test=0.892) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.891) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.901, test=0.889) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.896, test=0.897) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.898, test=0.906) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.908) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.908) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.899, test=0.895) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.899, test=0.896) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.895, test=0.892) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.891) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.901, test=0.889) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.896, test=0.897) total time=   0.5s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.905) total time=   0.4s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.908) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.902, test=0.908) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.899, test=0.895) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.899, test=0.896) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.899) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.895, test=0.892) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.891) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.901, test=0.889) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.896, test=0.897) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.898, test=0.906) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.908) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.902, test=0.908) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.899, test=0.895) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.899, test=0.897) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.899) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.896, test=0.890) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.891) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.901, test=0.887) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.897, test=0.895) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.898, test=0.904) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.902, test=0.906) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.902, test=0.905) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.899, test=0.895) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.899, test=0.896) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.899) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.895, test=0.892) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.891) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.901, test=0.888) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.897) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.898, test=0.905) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.902, test=0.908) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.899, test=0.895) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.899, test=0.896) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.899) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.895, test=0.892) total time=   0.4s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.891) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.901, test=0.889) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.896, test=0.897) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.905) total time=   0.4s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.908) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.902, test=0.908) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.899, test=0.895) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.894, test=0.894) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.894) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.890, test=0.883) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.894, test=0.889) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.884) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.889, test=0.891) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.894, test=0.901) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.909) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.898, test=0.905) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.893, test=0.885) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.894, test=0.894) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.894) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.890, test=0.883) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.894, test=0.889) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.884) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.890, test=0.891) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.894, test=0.901) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.909) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.898, test=0.905) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.893, test=0.885) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.893, test=0.892) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.896, test=0.893) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.889, test=0.884) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.894, test=0.888) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.898, test=0.883) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.889, test=0.887) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.892, test=0.899) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.906) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.898, test=0.905) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.892, test=0.884) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.894, test=0.894) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.894) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.890, test=0.883) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.894, test=0.889) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.884) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.890, test=0.891) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.894, test=0.901) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.909) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.898, test=0.905) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.893, test=0.885) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.894, test=0.894) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.894) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.890, test=0.883) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.894, test=0.889) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.884) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.890, test=0.890) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.894, test=0.901) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.909) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.898, test=0.905) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.893, test=0.885) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.894, test=0.894) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.894) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.890, test=0.883) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.894, test=0.889) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.884) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.889, test=0.891) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.894, test=0.901) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.909) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.898, test=0.905) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.893, test=0.885) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.894, test=0.894) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.894) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.890, test=0.883) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.894, test=0.889) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.884) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.890, test=0.891) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.894, test=0.901) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.909) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.898, test=0.905) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.893, test=0.885) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.893, test=0.892) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.896, test=0.893) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.889, test=0.884) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.894, test=0.888) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.898, test=0.883) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.889, test=0.887) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.892, test=0.899) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.906) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.898, test=0.905) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.892, test=0.884) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.894, test=0.894) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.894) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.890, test=0.883) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.894, test=0.889) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.884) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.890, test=0.891) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.894, test=0.901) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.909) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.898, test=0.905) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.893, test=0.885) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.893, test=0.894) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.894) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.890, test=0.883) total time=   0.4s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.894, test=0.889) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.884) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.889, test=0.891) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.894, test=0.901) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.909) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.898, test=0.905) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.893, test=0.885) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.894, test=0.894) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.894) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.890, test=0.883) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.894, test=0.889) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.897, test=0.884) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.889, test=0.891) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.894, test=0.901) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.900, test=0.909) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.898, test=0.905) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.893, test=0.885) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.894, test=0.894) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.894) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.890, test=0.883) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.894, test=0.889) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.897, test=0.884) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.890, test=0.891) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.894, test=0.901) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.900, test=0.909) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.898, test=0.905) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.893, test=0.885) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.893, test=0.892) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.896, test=0.893) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.889, test=0.884) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.894, test=0.888) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.898, test=0.883) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.889, test=0.887) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.892, test=0.899) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.900, test=0.906) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.898, test=0.905) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.892, test=0.884) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.894, test=0.894) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.894) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.890, test=0.883) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.894, test=0.889) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.897, test=0.884) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.889, test=0.891) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.894, test=0.901) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.900, test=0.909) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.898, test=0.905) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.893, test=0.885) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.894, test=0.894) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.894) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.890, test=0.883) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.894, test=0.889) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.897, test=0.884) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.890, test=0.891) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.894, test=0.901) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.900, test=0.908) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.898, test=0.905) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.01, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.893, test=0.886) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.918, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.923, test=0.916) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.912) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.921, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.923, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.916, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.917, test=0.922) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.927) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.927) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.918) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.918, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.923, test=0.916) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.912) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.921, test=0.916) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.923, test=0.910) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.916, test=0.915) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.917, test=0.922) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.927) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.927) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.918) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.919, test=0.918) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.924, test=0.916) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.911) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.915) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.923, test=0.911) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.916) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.917, test=0.922) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.928) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.927) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.918) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.923, test=0.916) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.912) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.923, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.915) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.917, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.927) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.927) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.918) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.918, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.923, test=0.916) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.912) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.921, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.923, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.916, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.917, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.927) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.927) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.918) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.918, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.923, test=0.916) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.912) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.921, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.923, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.916, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.917, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.927) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.927) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.918) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.918, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.923, test=0.916) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.912) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.921, test=0.916) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.923, test=0.910) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.916, test=0.915) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.917, test=0.922) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.927) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.927) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.918) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.919, test=0.918) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.924, test=0.916) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.911) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.915) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.923, test=0.911) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.916) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.917, test=0.922) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.928) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.927) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.918) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.923, test=0.916) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.912) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.923, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.916) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.917, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.927) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.927) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.918) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.918, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.923, test=0.916) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.912) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.921, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.923, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.916, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.917, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.927) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.927) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.918) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.918, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.923, test=0.916) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.912) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.921, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.923, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.916, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.917, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.927) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.927) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.918) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.918, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.923, test=0.916) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.912) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.921, test=0.916) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.923, test=0.910) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.916, test=0.915) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.917, test=0.922) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.927) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.927) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.918) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.919, test=0.918) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.924, test=0.916) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.911) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.915) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.923, test=0.911) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.916) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.917, test=0.922) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.928) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.927) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.918) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.923, test=0.916) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.912) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.923, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.915) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.917, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.927) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.927) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.918) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.918, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.923, test=0.916) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.912) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.921, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.923, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.916, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.917, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.927) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.927) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.918) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.917, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.923, test=0.915) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.911) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.911) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.916, test=0.923) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.924) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.921, test=0.928) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.916) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.917, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.923, test=0.915) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.911) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.916) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.911) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.915) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.916, test=0.923) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.924) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.921, test=0.928) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.916) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.917, test=0.918) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.923, test=0.914) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.911) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.916) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.912) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.915) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.916, test=0.922) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.924) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.921, test=0.927) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.915) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.917, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.923, test=0.915) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.911) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.911) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.923) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.924) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.928) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.917, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.923, test=0.915) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.911) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.911) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.914) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.917, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.924) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.921, test=0.928) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.917, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.923, test=0.915) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.911) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.911) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.916, test=0.923) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.924) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.921, test=0.928) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.917, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.923, test=0.915) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.911) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.916) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.911) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.915) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.916, test=0.923) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.924) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.921, test=0.928) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.916) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.917, test=0.918) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.923, test=0.914) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.911) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.916) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.912) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.915) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.916, test=0.922) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.924) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.921, test=0.927) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.915) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.917, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.923, test=0.915) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.911) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.911) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.924) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.928) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.917, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.923, test=0.915) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.911) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.911) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.916, test=0.923) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.924) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.921, test=0.928) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.917, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.923, test=0.915) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.911) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.911) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.916, test=0.923) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.924) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.921, test=0.928) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.917, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.923, test=0.915) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.911) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.916) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.911) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.915) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.916, test=0.923) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.924) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.921, test=0.928) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.916) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.917, test=0.918) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.923, test=0.914) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.911) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.916) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.912) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.915) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.916, test=0.922) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.924) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.921, test=0.927) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.915) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.917, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.923, test=0.915) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.911) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.911) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.914) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.923) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.924) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.928) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.917, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.923, test=0.915) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.911) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.911) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.915) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.916, test=0.922) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.924) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.921, test=0.928) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.916) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.921, test=0.913) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.914, test=0.907) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.919, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.913, test=0.912) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.916, test=0.920) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.920) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.919, test=0.925) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.921, test=0.913) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.914, test=0.907) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.918, test=0.915) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.919, test=0.910) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.913, test=0.912) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.916, test=0.920) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.920) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.919, test=0.925) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.918, test=0.915) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.917) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.921, test=0.913) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.914, test=0.907) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.918, test=0.915) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.919, test=0.911) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.913, test=0.913) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.916, test=0.921) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.920) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.919, test=0.925) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.918, test=0.915) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.913) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.914, test=0.907) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.919, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.913, test=0.912) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.920) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.921) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.919, test=0.925) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.916, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.921, test=0.913) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.914, test=0.907) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.919, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.914, test=0.912) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.916, test=0.920) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.921) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.919, test=0.925) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.921, test=0.913) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.914, test=0.907) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.919, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.913, test=0.912) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.916, test=0.920) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.920) total time=   0.4s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.919, test=0.925) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.921, test=0.913) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.914, test=0.907) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.918, test=0.915) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.919, test=0.910) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.913, test=0.912) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.916, test=0.920) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.920) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.919, test=0.925) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.918, test=0.915) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.917) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.921, test=0.913) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.914, test=0.907) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.918, test=0.915) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.919, test=0.911) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.913, test=0.913) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.916, test=0.921) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.920) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.919, test=0.925) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.918, test=0.915) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.913) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.914, test=0.907) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.919, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.913, test=0.912) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.920) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.921) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.919, test=0.925) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.921, test=0.913) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.914, test=0.907) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.919, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.913, test=0.912) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.916, test=0.920) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.920) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.919, test=0.925) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.915, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.921, test=0.913) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.914, test=0.907) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.919, test=0.910) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.913, test=0.912) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.916, test=0.920) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.920, test=0.920) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.919, test=0.925) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.918, test=0.915) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.915, test=0.917) total time=   0.2s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.921, test=0.913) total time=   0.2s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.914, test=0.907) total time=   0.2s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.918, test=0.915) total time=   0.2s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.919, test=0.910) total time=   0.2s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.913, test=0.912) total time=   0.2s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.916, test=0.920) total time=   0.2s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.920, test=0.920) total time=   0.2s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.919, test=0.925) total time=   0.2s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.918, test=0.915) total time=   0.2s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.915, test=0.917) total time=   0.1s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.921, test=0.913) total time=   0.1s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.914, test=0.907) total time=   0.1s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.918, test=0.915) total time=   0.1s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.919, test=0.911) total time=   0.1s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.913, test=0.913) total time=   0.1s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.916, test=0.921) total time=   0.1s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.920, test=0.920) total time=   0.1s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.919, test=0.925) total time=   0.1s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.918, test=0.915) total time=   0.1s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.913) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.914, test=0.907) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.919, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.913, test=0.912) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.920) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.921) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.919, test=0.925) total time=   0.3s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.915, test=0.917) total time=   0.3s\n",
      "[CV 2/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.921, test=0.913) total time=   0.3s\n",
      "[CV 3/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.914, test=0.907) total time=   0.3s\n",
      "[CV 4/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 5/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.919, test=0.910) total time=   0.3s\n",
      "[CV 6/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.913, test=0.912) total time=   0.3s\n",
      "[CV 7/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.916, test=0.920) total time=   0.3s\n",
      "[CV 8/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.920, test=0.921) total time=   0.3s\n",
      "[CV 9/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.919, test=0.925) total time=   0.4s\n",
      "[CV 10/10] END lr__C=0.1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.918, test=0.915) total time=   0.3s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.924) total time=   0.7s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.925) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.924, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.929) total time=   0.3s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.926, test=0.925) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.929) total time=   0.3s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.926) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.925) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.925) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.924, test=0.920) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.929) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.923) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.926, test=0.925) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.929) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.934) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.926) total time=   0.3s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.925) total time=   0.1s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.925) total time=   0.2s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.924, test=0.920) total time=   0.2s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.929) total time=   0.2s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.923) total time=   0.1s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.926, test=0.925) total time=   0.2s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.929) total time=   0.2s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.1s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.934) total time=   0.1s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.926) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.925) total time=   0.5s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.925) total time=   0.6s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.924, test=0.920) total time=   0.8s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.929) total time=   0.5s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.923) total time=   0.6s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.926, test=0.925) total time=   0.7s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.929) total time=   0.7s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   0.6s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.934) total time=   0.7s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.926) total time=   0.6s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.924) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.925) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.924, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.929) total time=   0.5s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.926, test=0.925) total time=   0.5s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.929) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.926) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.924) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.925) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.924, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.929) total time=   0.3s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.926, test=0.925) total time=   0.5s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.929) total time=   0.3s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.926) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.924) total time=   0.3s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.925) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.924, test=0.920) total time=   0.3s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.929) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.926, test=0.925) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.929) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.926) total time=   0.3s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.925) total time=   0.1s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.925) total time=   0.2s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.924, test=0.920) total time=   0.2s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.929) total time=   0.2s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.923) total time=   0.1s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.926, test=0.925) total time=   0.2s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.929) total time=   0.2s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.1s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.934) total time=   0.1s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.926) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.924) total time=   0.5s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.925) total time=   0.7s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.924, test=0.920) total time=   0.6s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.929) total time=   0.5s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.923) total time=   0.5s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.926, test=0.925) total time=   0.5s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.929) total time=   0.7s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   0.5s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.934) total time=   0.7s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.926) total time=   0.5s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.924) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.925) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.924, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.929) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.926, test=0.925) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.929) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.926) total time=   0.5s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.924) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.925) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.924, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.929) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.926, test=0.925) total time=   0.5s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.929) total time=   0.3s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.926) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.924) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.925) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.924, test=0.920) total time=   0.3s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.929) total time=   0.3s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.926, test=0.925) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.929) total time=   0.3s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.926) total time=   0.3s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.925) total time=   0.1s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.925) total time=   0.2s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.924, test=0.920) total time=   0.2s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.929) total time=   0.2s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.923) total time=   0.1s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.926, test=0.925) total time=   0.2s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.929) total time=   0.2s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.1s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.934) total time=   0.1s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.926) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.925) total time=   0.6s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.925) total time=   0.6s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.924, test=0.920) total time=   0.7s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.929) total time=   0.6s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.923) total time=   0.7s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.926, test=0.925) total time=   0.6s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.929) total time=   0.5s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   0.5s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.934) total time=   0.5s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.926) total time=   0.5s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.924) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.925) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.924, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.929) total time=   0.5s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.926, test=0.925) total time=   0.5s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.929) total time=   0.5s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.926) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.924) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.925, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.928) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.924, test=0.922) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.927, test=0.928) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.925) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.927, test=0.928) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.924) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.925, test=0.920) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.928) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.923) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.924, test=0.922) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.927, test=0.928) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.934) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.925) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.927, test=0.928) total time=   0.2s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.924) total time=   0.2s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.925, test=0.919) total time=   0.2s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.929) total time=   0.2s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.923) total time=   0.2s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.924, test=0.922) total time=   0.2s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.927, test=0.928) total time=   0.2s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.2s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.934) total time=   0.2s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.924) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.927, test=0.928) total time=   0.7s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.924) total time=   0.7s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.925, test=0.920) total time=   0.7s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.928) total time=   0.5s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.923) total time=   0.6s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.924, test=0.922) total time=   0.7s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.927, test=0.928) total time=   0.8s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   0.8s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.934) total time=   0.7s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.925) total time=   0.8s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.924) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.925, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.928) total time=   0.5s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.924, test=0.922) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.927, test=0.928) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.925) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.924) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.925, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.928) total time=   0.3s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.924, test=0.922) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.927, test=0.928) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.925) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.928) total time=   0.3s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.924) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.925, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.928) total time=   0.3s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.923) total time=   0.3s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.924, test=0.922) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.927, test=0.928) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.3s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.925) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.927, test=0.928) total time=   0.2s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.924) total time=   0.2s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.925, test=0.919) total time=   0.2s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.929) total time=   0.2s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.923) total time=   0.2s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.924, test=0.922) total time=   0.2s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.927, test=0.928) total time=   0.2s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.2s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.934) total time=   0.2s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.924) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.927, test=0.928) total time=   0.8s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.924) total time=   0.7s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.925, test=0.920) total time=   0.7s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.929) total time=   0.6s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.923) total time=   1.0s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.924, test=0.922) total time=   0.8s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.927, test=0.928) total time=   0.8s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   0.9s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.934) total time=   0.6s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.925) total time=   0.7s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.924) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.925, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.928) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.924, test=0.922) total time=   0.5s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.927, test=0.928) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.925) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.924) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.925, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.928) total time=   0.5s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.924, test=0.922) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.927, test=0.928) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.925) total time=   0.3s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.928) total time=   0.3s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.924) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.925, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.928) total time=   0.3s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.924, test=0.922) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.927, test=0.928) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.3s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.934) total time=   0.3s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.925) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.927, test=0.928) total time=   0.2s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.924) total time=   0.2s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.925, test=0.919) total time=   0.2s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.929) total time=   0.2s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.923) total time=   0.2s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.924, test=0.922) total time=   0.2s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.927, test=0.928) total time=   0.2s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.2s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.934) total time=   0.2s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.924) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.928) total time=   0.8s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.924) total time=   0.8s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.925, test=0.920) total time=   0.8s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.929) total time=   0.7s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.923) total time=   0.8s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.924, test=0.922) total time=   0.6s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.927, test=0.928) total time=   0.8s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   1.0s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.934) total time=   0.8s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.925) total time=   0.9s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.924) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.925, test=0.920) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.928) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.923) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.924, test=0.922) total time=   0.5s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.927, test=0.928) total time=   0.6s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.934) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.925) total time=   0.5s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.926, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.922) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.925, test=0.918) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.926) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.922) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.924) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.927, test=0.925) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   0.3s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.932) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.921) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.926, test=0.928) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.922) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.925, test=0.918) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.926) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.922) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.924) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.927, test=0.925) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.933) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.921) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.926, test=0.928) total time=   0.2s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.922) total time=   0.2s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.925, test=0.918) total time=   0.2s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.926) total time=   0.2s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.922) total time=   0.3s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.924) total time=   0.2s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.927, test=0.925) total time=   0.2s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.2s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.932) total time=   0.2s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.921) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.926, test=0.928) total time=   0.8s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.922) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.925, test=0.918) total time=   1.1s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.926) total time=   0.7s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.921) total time=   0.8s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.924) total time=   0.7s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.927, test=0.925) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.931) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.932) total time=   1.1s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.921) total time=   0.8s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.926, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.922) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.925, test=0.918) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.926) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.922) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.924) total time=   0.5s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.927, test=0.925) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.932) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.921) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.926, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.922) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.925, test=0.918) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.926) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.922) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.924) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.927, test=0.925) total time=   0.3s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.932) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.921) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.926, test=0.928) total time=   0.3s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.922) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.925, test=0.918) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.926) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.922) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.924) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.927, test=0.925) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.932) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.921) total time=   0.3s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.926, test=0.928) total time=   0.2s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.922) total time=   0.2s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.925, test=0.918) total time=   0.2s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.926) total time=   0.2s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.922) total time=   0.2s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.924) total time=   0.2s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.927, test=0.925) total time=   0.2s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.2s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.932) total time=   0.2s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.921) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.926, test=0.928) total time=   0.7s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.922) total time=   0.7s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.925, test=0.918) total time=   1.0s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.926) total time=   0.9s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.922) total time=   0.9s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.924) total time=   0.7s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.927, test=0.925) total time=   1.1s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.931) total time=   0.8s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.932) total time=   1.3s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.921) total time=   0.7s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.926, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.922) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.925, test=0.918) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.926) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.922) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.924) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.927, test=0.925) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.932) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.921) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.926, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.922) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.925, test=0.918) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.926) total time=   0.3s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.922) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.922, test=0.924) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.927, test=0.925) total time=   0.3s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   0.3s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.932) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.921) total time=   0.4s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.926, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.922) total time=   0.3s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.925, test=0.918) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.926) total time=   0.4s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.922) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.922, test=0.924) total time=   0.4s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.927, test=0.925) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   0.3s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.932) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.921) total time=   0.3s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.926, test=0.928) total time=   0.2s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.922) total time=   0.2s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.925, test=0.918) total time=   0.2s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.926) total time=   0.2s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.922) total time=   0.2s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.922, test=0.924) total time=   0.2s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.927, test=0.925) total time=   0.2s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.2s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.932) total time=   0.2s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.921) total time=   0.2s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.926, test=0.928) total time=   1.1s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.922) total time=   0.6s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.925, test=0.918) total time=   0.8s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.926) total time=   0.6s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.922) total time=   0.7s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.924) total time=   1.0s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.927, test=0.925) total time=   0.7s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.931) total time=   0.9s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.932) total time=   0.8s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.921) total time=   0.8s\n",
      "[CV 1/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.926, test=0.928) total time=   0.4s\n",
      "[CV 2/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.922) total time=   0.4s\n",
      "[CV 3/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.925, test=0.918) total time=   0.4s\n",
      "[CV 4/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.926) total time=   0.5s\n",
      "[CV 5/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.922) total time=   0.4s\n",
      "[CV 6/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.922, test=0.924) total time=   0.5s\n",
      "[CV 7/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.927, test=0.925) total time=   0.4s\n",
      "[CV 8/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   0.4s\n",
      "[CV 9/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.932) total time=   0.4s\n",
      "[CV 10/10] END lr__C=1, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.921) total time=   0.4s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.929) total time=   0.5s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.928) total time=   0.5s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.926) total time=   0.5s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=   0.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.927) total time=   0.5s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.931) total time=   0.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   0.5s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.934) total time=   0.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.938) total time=   0.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.928) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.929) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.928) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.925) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.926) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.929) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.931) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.934) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.937) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.928) total time=   0.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.929) total time=   0.3s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.928) total time=   0.2s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.925) total time=   0.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   0.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.927) total time=   0.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.931) total time=   0.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.931) total time=   0.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.934) total time=   0.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.938) total time=   0.2s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.928) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.929) total time=   1.1s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.928) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.926) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.927) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.931) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.934) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.937) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.929) total time=   1.1s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.929) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.928) total time=   1.2s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.925) total time=   0.9s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   1.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.927) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.931) total time=   1.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.934) total time=   0.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.938) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.928) total time=   0.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.929) total time=   0.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.928) total time=   0.6s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.926) total time=   0.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=   0.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.927) total time=   0.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.931) total time=   0.7s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   0.6s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.934) total time=   0.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.938) total time=   0.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.928) total time=   0.6s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.929) total time=   0.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.928) total time=   0.7s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.925) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.931) total time=   0.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.927) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.930) total time=   0.7s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.931) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.934) total time=   0.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.938) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.928) total time=   0.7s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.929) total time=   0.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.928) total time=   0.2s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.925) total time=   0.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   0.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.927) total time=   0.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.931) total time=   0.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.931) total time=   0.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.934) total time=   0.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.938) total time=   0.2s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.928) total time=   0.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.928) total time=   1.3s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.928) total time=   1.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.925) total time=   1.5s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=   0.9s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.927) total time=   1.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.930) total time=   1.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   1.1s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.934) total time=   1.1s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.938) total time=   1.4s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.928) total time=   1.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.929) total time=   0.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.928) total time=   1.4s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.925) total time=   0.9s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   1.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.927) total time=   1.0s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.931) total time=   1.4s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.934) total time=   1.0s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.938) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.928) total time=   0.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.929) total time=   0.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.928) total time=   0.6s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.926) total time=   0.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=   0.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.927) total time=   0.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.931) total time=   0.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.934) total time=   0.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.938) total time=   0.5s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.928) total time=   0.6s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.929) total time=   0.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.928) total time=   0.7s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.925) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.931) total time=   0.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.927) total time=   0.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.930) total time=   0.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.931) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.934) total time=   0.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.938) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.928) total time=   0.7s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.929) total time=   0.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.928) total time=   0.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.925) total time=   0.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   0.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.927) total time=   0.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.931) total time=   0.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.931) total time=   0.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.934) total time=   0.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.938) total time=   0.2s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.928) total time=   0.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.928) total time=   1.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.928) total time=   1.2s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.925) total time=   1.5s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=   1.0s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.927) total time=   1.1s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.930) total time=   0.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   1.4s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.934) total time=   1.8s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.938) total time=   1.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.928) total time=   1.4s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.929) total time=   0.9s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.928) total time=   1.5s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.925) total time=   0.9s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   1.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.927) total time=   1.0s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.931) total time=   1.3s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.934) total time=   1.0s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.938) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.928) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   0.5s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.926) total time=   0.5s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.920) total time=   0.5s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   0.5s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.927) total time=   0.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.930) total time=   0.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.929) total time=   0.6s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.935) total time=   0.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.936) total time=   0.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.929) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.930) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.926) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.921) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.926) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.930) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.929) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.935) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.936) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.929) total time=   0.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.926) total time=   0.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.920) total time=   0.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   0.3s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.927) total time=   0.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.930) total time=   0.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.929) total time=   0.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.935) total time=   0.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.936) total time=   0.2s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.929) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.926) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.921) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.929) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.931) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.929) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.918) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.932) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.929) total time=   1.1s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.926) total time=   1.2s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.921) total time=   0.9s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   1.1s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.927) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.930) total time=   1.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.929) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.935) total time=   1.0s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.936) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.929) total time=   0.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   0.5s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.926) total time=   0.5s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.920) total time=   0.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   0.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.927) total time=   0.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.930) total time=   0.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.929) total time=   0.6s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.935) total time=   0.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.936) total time=   0.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.929) total time=   0.5s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   0.5s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.926) total time=   0.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.920) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   0.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.927) total time=   0.8s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.930) total time=   0.9s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.929) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.935) total time=   0.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.936) total time=   0.5s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.929) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.926) total time=   0.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.920) total time=   0.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   0.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.927) total time=   0.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.930) total time=   0.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.929) total time=   0.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.935) total time=   0.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.936) total time=   0.2s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.929) total time=   0.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.931) total time=   1.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.926) total time=   3.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.920) total time=   1.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   2.0s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.927) total time=   2.1s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.930) total time=   1.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.929) total time=   4.4s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.935) total time=   3.3s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.936) total time=   3.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.929) total time=   3.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   0.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.926) total time=   1.4s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.921) total time=   1.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   1.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.927) total time=   1.0s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.930) total time=   1.4s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.929) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.935) total time=   0.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.936) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.929) total time=   0.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   0.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.926) total time=   0.6s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.920) total time=   0.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   0.5s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.927) total time=   0.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.930) total time=   0.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.929) total time=   0.6s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.935) total time=   0.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.936) total time=   0.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.929) total time=   0.5s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   0.5s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.926) total time=   0.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.920) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   0.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.927) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.930) total time=   0.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.929) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.935) total time=   0.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.936) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.929) total time=   0.7s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.926) total time=   0.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.920) total time=   0.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   0.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.927) total time=   0.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.930) total time=   0.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.929) total time=   0.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.935) total time=   0.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.936) total time=   0.2s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.929) total time=   0.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.931) total time=   2.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.926) total time=   2.9s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.920) total time=   3.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   1.5s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.927) total time=   1.3s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.930) total time=   4.0s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.928) total time=   2.3s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.935) total time=   4.3s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.936) total time=   3.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.929) total time=   1.3s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   0.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.926) total time=   1.4s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.921) total time=   1.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   1.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.927) total time=   1.0s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.930) total time=   1.4s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.929) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.935) total time=   0.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.936) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.929) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.934) total time=   0.5s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.926) total time=   0.5s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.922) total time=   0.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.929) total time=   0.5s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.928) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.931) total time=   1.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.928) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.935) total time=   0.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   0.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.930) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.926) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.922) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.929) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.928) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.930) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.929) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.935) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.929) total time=   0.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.934) total time=   0.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.926) total time=   0.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.922) total time=   0.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.929) total time=   0.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.928) total time=   0.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.931) total time=   0.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.928) total time=   0.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.935) total time=   0.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   0.2s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.930) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.924, test=0.918) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.926) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.927, test=0.922) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.924) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.920, test=0.918) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.929) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.930) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.936) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.931) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.929) total time=   1.1s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.934) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.926) total time=   1.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.922) total time=   1.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.929) total time=   1.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.928) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.932) total time=   1.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.928) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.935) total time=   0.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.930) total time=   0.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.934) total time=   0.7s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.926) total time=   0.5s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.922) total time=   0.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.929) total time=   0.7s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.928) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.931) total time=   0.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.928) total time=   0.6s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.935) total time=   0.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   0.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.930) total time=   0.5s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.934) total time=   0.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.926) total time=   0.7s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.922) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.929) total time=   0.7s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.928) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.931) total time=   0.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.928) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.935) total time=   0.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.933) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.930) total time=   1.1s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.934) total time=   0.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.926) total time=   0.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.922) total time=   0.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.929) total time=   0.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.928) total time=   0.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.931) total time=   0.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.928) total time=   0.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.935) total time=   0.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   0.2s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.930) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.931) total time=   5.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.926) total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.899, test=0.895) total time=   5.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.929) total time=   2.8s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.928) total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.931) total time=   5.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.928) total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.935) total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.922, test=0.919) total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.926) total time=   5.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.934) total time=   0.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.926) total time=   1.4s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.922) total time=   0.9s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.929) total time=   1.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.928) total time=   1.1s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.932) total time=   1.3s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.928) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.935) total time=   0.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.930) total time=   0.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.934) total time=   0.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.926) total time=   0.5s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.922) total time=   0.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.929) total time=   0.5s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.928) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.928, test=0.931) total time=   0.5s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.928) total time=   0.5s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.935) total time=   0.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.930) total time=   0.5s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.934) total time=   0.5s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.926) total time=   0.7s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.922) total time=   0.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.929) total time=   0.7s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.928) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.928, test=0.931) total time=   0.7s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.928) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.935) total time=   0.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.933) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.930) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.934) total time=   0.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.926) total time=   0.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.922) total time=   0.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.929) total time=   0.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.928) total time=   0.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.928, test=0.931) total time=   0.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.928) total time=   0.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.935) total time=   0.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   0.2s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.930) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=  10.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.926) total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.922) total time=  10.5s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.929) total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.926) total time=  10.3s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.931) total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.927) total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.932) total time=  10.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.931) total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.925) total time=  10.3s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.934) total time=   0.7s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.926) total time=   1.4s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.922) total time=   0.9s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.929) total time=   1.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.928) total time=   1.0s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.928, test=0.931) total time=   1.3s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.928) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.935) total time=   0.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   1.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.930) total time=   0.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.929) total time=   0.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.938, test=0.926) total time=   0.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.925) total time=   0.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.934) total time=   0.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.930) total time=   0.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   0.7s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   0.7s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.935) total time=   0.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.938) total time=   0.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.930) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.928) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.928) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.924) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.933) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.930) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.930) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.935) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.938) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.930) total time=   0.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.929) total time=   0.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.938, test=0.926) total time=   0.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.925) total time=   0.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.934) total time=   0.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.930) total time=   0.3s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.935) total time=   0.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.938) total time=   0.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.931) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.931) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.927) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.921) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.933) total time=   1.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.930) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.931) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.931) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.935) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.938) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.930) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.929) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.938, test=0.928) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.925) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.933) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.929) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.935) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.938) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.930) total time=   1.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.929) total time=   0.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.938, test=0.926) total time=   0.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.925) total time=   1.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.934) total time=   1.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.930) total time=   1.1s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   0.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   0.7s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.935) total time=   0.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.938) total time=   0.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.930) total time=   0.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.929) total time=   0.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.938, test=0.926) total time=   1.0s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.925) total time=   0.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.934) total time=   0.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.931) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   1.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.935) total time=   0.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.938) total time=   0.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.931) total time=   0.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.929) total time=   0.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.938, test=0.926) total time=   0.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.925) total time=   0.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.934) total time=   0.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.930) total time=   0.3s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.935) total time=   0.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.938) total time=   0.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.931) total time=   0.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.929) total time=   1.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.938, test=0.926) total time=   2.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.925) total time=   2.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.934) total time=   1.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.931) total time=   1.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.931) total time=   1.5s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   1.0s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.935) total time=   2.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.938) total time=   1.5s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.930) total time=   1.1s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.929) total time=   1.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.926) total time=   4.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.925) total time=   1.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.934) total time=   1.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.930) total time=   1.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   2.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   1.4s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.935) total time=   1.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.938) total time=   2.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.931) total time=   1.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.929) total time=   0.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.938, test=0.926) total time=   0.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.925) total time=   0.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.934) total time=   0.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.930) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   0.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   0.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.935) total time=   0.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.938) total time=   0.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.930) total time=   0.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.929) total time=   0.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.938, test=0.926) total time=   1.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.925) total time=   0.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.934) total time=   0.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.931) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   1.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.935) total time=   0.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.938) total time=   0.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.931) total time=   0.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.929) total time=   0.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.938, test=0.926) total time=   0.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.925) total time=   0.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.934) total time=   0.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.930) total time=   0.3s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.935) total time=   0.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.938) total time=   0.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.931) total time=   0.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.929) total time=   1.6s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.938, test=0.926) total time=   2.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.925) total time=   2.4s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.933) total time=   1.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.931) total time=   6.3s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.931) total time=   1.7s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   1.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.935) total time=   3.2s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.938) total time=   1.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.930) total time=   1.5s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.929) total time=   1.6s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.926) total time=   4.6s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.925) total time=   1.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.934) total time=   1.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.930) total time=   1.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   2.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   1.6s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.935) total time=   2.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.938) total time=   2.4s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.931) total time=   1.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.934) total time=   0.9s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.926) total time=   0.9s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.923) total time=   1.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.932) total time=   0.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.930) total time=   0.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.933) total time=   0.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   0.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.937) total time=   0.7s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.936) total time=   0.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.930) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.926) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.923) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.932) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.929) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.932) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.931) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.936) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.936) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.929) total time=   0.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.934) total time=   0.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.926) total time=   0.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.923) total time=   0.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.932) total time=   0.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.930) total time=   0.4s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.933) total time=   0.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.937) total time=   0.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.936) total time=   0.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.930) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.925, test=0.919) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.927) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.923) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.931) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.921) total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.932) total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.931) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.935) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.917) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.931) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.934) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.927) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.923) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.932) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.929) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.934) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.936) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.936) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.930) total time=   1.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.934) total time=   0.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.926) total time=   0.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.923) total time=   0.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.932) total time=   1.4s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.930) total time=   1.2s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.933) total time=   0.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.937) total time=   0.6s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.936) total time=   0.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.930) total time=   0.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.926) total time=   1.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.923) total time=   1.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.932) total time=   1.0s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.930) total time=   0.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.933) total time=   1.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   1.0s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.937) total time=   0.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.936) total time=   0.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.930) total time=   0.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.934) total time=   0.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.926) total time=   0.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.923) total time=   0.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.932) total time=   0.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.930) total time=   0.3s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.933) total time=   0.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.937) total time=   0.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.936) total time=   0.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.930) total time=   0.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.934) total time=   3.6s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.927) total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.924, test=0.921) total time=   5.5s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.932) total time=   2.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.929) total time=   3.7s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.933) total time=   1.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   3.6s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.937) total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.935) total time=   5.4s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.930) total time=   2.1s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.934) total time=   1.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.927) total time=   4.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.923) total time=   1.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.932) total time=   1.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.929) total time=   1.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.933) total time=   2.4s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   1.4s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.937) total time=   1.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.936) total time=   2.4s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.930) total time=   1.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.934) total time=   0.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.926) total time=   0.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.923) total time=   0.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.932) total time=   0.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.930) total time=   0.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.933) total time=   0.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.937) total time=   0.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.936) total time=   0.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.930) total time=   1.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=   1.1s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.926) total time=   1.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.923) total time=   1.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.932) total time=   1.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.930) total time=   0.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.933) total time=   1.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   1.0s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.937) total time=   0.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.936) total time=   1.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.930) total time=   1.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.934) total time=   0.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.926) total time=   0.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.923) total time=   0.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.932) total time=   0.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.930) total time=   0.3s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.933) total time=   0.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.937) total time=   0.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.936) total time=   0.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.930) total time=   0.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.934) total time=   2.8s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.927) total time=   2.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.923) total time=   2.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.932) total time=   2.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.929) total time=   2.7s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.934) total time=   1.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   1.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.936) total time=   1.4s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.936) total time=   6.7s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.930) total time=   1.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.934) total time=   1.6s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.927) total time=   4.9s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.923) total time=   2.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.932) total time=   1.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.929) total time=   1.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.933) total time=   2.4s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   1.6s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.937) total time=   2.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.936) total time=   2.6s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.930) total time=   1.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   0.8s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.928) total time=   0.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.923) total time=   0.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   1.4s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.928) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.933) total time=   0.7s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   0.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.938) total time=   0.7s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=   0.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.930) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.933) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.927) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.923) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.930) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.929) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.932) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.937) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.934) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.930) total time=   0.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   0.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.928) total time=   0.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.923) total time=   0.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.928) total time=   0.4s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.933) total time=   0.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.938) total time=   0.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   0.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.930) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.924, test=0.915) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.927) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.918, test=0.911) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.930) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.929) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.926, test=0.929) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.929) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.937) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.930) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.927) total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.928) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.923) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.929) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.932) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.937) total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.930) total time=   1.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   0.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.928) total time=   0.9s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.923) total time=   0.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   1.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.928) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.933) total time=   0.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   0.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.938) total time=   0.7s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=   0.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.930) total time=   0.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.933) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.928) total time=   1.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.923) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   1.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.928) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.933) total time=   1.2s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   1.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.938) total time=   1.1s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=   1.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.930) total time=   1.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   0.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.928) total time=   0.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.923) total time=   0.4s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.928) total time=   0.4s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.933) total time=   0.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.938) total time=   0.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   0.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.930) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.934) total time=   5.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.928) total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.919) total time=   5.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.928) total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.930) total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.928) total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.935) total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.936) total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   5.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   1.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.928) total time=   4.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.923) total time=   1.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   1.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.929) total time=   1.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.933) total time=   2.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   1.4s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.938) total time=   1.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=   2.5s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.930) total time=   1.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   0.8s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.928) total time=   0.9s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.929, test=0.923) total time=   0.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   0.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.928) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.933) total time=   0.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   1.6s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.937, test=0.938) total time=   0.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=   0.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.930) total time=   0.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.933) total time=   0.8s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.928) total time=   1.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.923) total time=   0.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   1.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.928) total time=   0.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.933) total time=   1.2s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   1.0s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.937, test=0.938) total time=   1.1s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=   0.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.930) total time=   0.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   0.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.928) total time=   0.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.929, test=0.923) total time=   0.4s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.928) total time=   0.4s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.933) total time=   0.4s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.937, test=0.938) total time=   0.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   0.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.930) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.927) total time=  11.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.937, test=0.928) total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.921, test=0.915) total time=  11.2s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.926) total time=  10.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.933) total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.928, test=0.929) total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.938) total time=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.915, test=0.913) total time=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.928) total time=  10.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   1.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.928) total time=   4.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.929, test=0.923) total time=   1.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   1.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.929) total time=   1.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.933) total time=   2.2s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   1.4s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.937, test=0.938) total time=   2.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=   2.4s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.930) total time=   1.8s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 75\n",
      "n_resources: 39801\n",
      "Fitting 10 folds for each of 75 candidates, totalling 750 fits\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.935) total time=   0.7s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   0.7s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.932) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.931) total time=   0.8s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.931) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.929) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.935) total time=   0.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   0.7s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.932) total time=   0.8s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.931) total time=   0.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.931) total time=   0.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.929) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.935) total time=   0.7s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   0.7s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.932) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.7s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.931) total time=   0.8s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.931) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.929) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.935) total time=   4.1s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   2.6s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.933) total time=   2.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   2.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=   2.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   2.3s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   3.6s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.931) total time=   3.8s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.931) total time=   2.9s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.929) total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.935) total time=   4.1s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   2.6s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.933) total time=   2.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   2.4s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=   2.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   2.3s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   3.5s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.931) total time=   3.7s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.931) total time=   2.9s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.929) total time=   2.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.935) total time=   4.4s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   2.4s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.933) total time=   2.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   2.3s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=   2.3s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   2.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   3.6s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.931) total time=   3.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.931) total time=   2.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.929) total time=   2.7s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.934) total time=   3.4s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.930) total time=   2.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.932) total time=   2.5s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   2.5s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.931) total time=   3.1s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   3.0s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.932) total time=   3.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.932) total time=   3.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   3.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.928) total time=   2.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.934) total time=   3.4s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.930) total time=   3.0s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.932) total time=   2.5s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   2.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.931) total time=   2.9s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   3.1s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.932) total time=   3.3s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.932) total time=   3.4s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   3.1s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.928) total time=   3.0s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=   3.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.930) total time=   3.1s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.932) total time=   3.1s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   3.0s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.931) total time=   2.8s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.0s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.932) total time=   3.0s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.932) total time=   3.1s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.5s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.928) total time=   3.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=   3.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.930) total time=   4.0s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.932) total time=   3.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   3.4s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.931) total time=   3.0s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.2s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.932) total time=   3.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.932) total time=   3.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.928) total time=   3.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=   3.3s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.930) total time=   3.3s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.932) total time=   3.4s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   3.4s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.931) total time=   3.3s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.1s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.930, test=0.932) total time=   3.1s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.932) total time=   3.3s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.4s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.928) total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.934) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.929) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.929, test=0.931) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.930) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.931) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.932) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.932) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.929) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.929) total time=   0.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   1.1s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.930) total time=   0.9s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.932) total time=   0.8s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.8s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.931) total time=   0.8s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.932) total time=   0.9s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.932) total time=   1.0s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.9s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.928) total time=   0.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   1.1s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.930) total time=   0.9s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.932) total time=   0.9s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.9s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.931) total time=   0.9s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.9s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.932) total time=   0.9s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.932) total time=   1.0s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.928) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   1.0s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.930) total time=   0.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.932) total time=   0.8s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.8s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.931) total time=   0.8s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.930, test=0.932) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.932) total time=   0.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.928) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=   4.4s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.930) total time=   2.7s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.932) total time=   2.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   2.3s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.931) total time=   2.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.932) total time=   4.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=   3.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.928) total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=   4.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.930) total time=   2.7s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.932) total time=   2.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   2.4s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.931) total time=   2.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.932) total time=   4.3s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=   3.7s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.928) total time=   2.7s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=   4.4s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.930) total time=   2.7s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.932) total time=   1.9s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   2.5s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.931) total time=   2.6s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.3s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.930, test=0.932) total time=   5.2s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=   3.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.928) total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.936) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.932) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.934) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.932) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.929) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.929) total time=   0.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.936) total time=   2.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.933) total time=   3.4s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   3.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=   3.7s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   6.5s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=   2.5s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.934) total time=   3.1s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.931) total time=   3.7s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   2.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   4.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.937) total time=   4.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   2.7s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   2.4s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   2.3s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=   2.3s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.934) total time=   2.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   3.7s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.9s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.9s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.936) total time=   3.2s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.933) total time=   4.0s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   4.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   3.4s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   3.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=   3.4s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.934) total time=   3.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.931) total time=   2.3s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   2.9s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.929) total time=   3.3s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.937) total time=   3.6s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.933) total time=   3.0s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   2.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.931) total time=   2.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   2.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=   2.9s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.934) total time=   3.1s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   3.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   2.6s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   2.5s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.937) total time=   3.4s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.933) total time=   3.1s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   2.6s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.931) total time=   2.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   2.8s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=   2.9s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.934) total time=   2.4s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   3.2s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   2.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   2.5s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.937) total time=   2.9s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   2.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   4.4s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=   2.7s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   2.9s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=   3.4s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.934) total time=   3.3s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   2.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.5s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.1s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.937) total time=   2.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   2.7s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   4.2s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=   2.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   2.9s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=   3.3s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.934) total time=   3.4s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   3.0s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.5s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.2s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.937) total time=   2.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   2.6s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   3.8s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=   3.6s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   3.1s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=   3.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.934) total time=   3.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   3.1s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   3.1s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.937) total time=   4.1s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   2.5s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.1s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   2.4s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   2.3s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=   2.6s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.934) total time=   2.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   3.6s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   3.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.937) total time=   0.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   0.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   0.8s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.8s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   0.7s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.934) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.8s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.7s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.937) total time=   0.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   0.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   0.8s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   0.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.934) total time=   0.8s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.8s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.7s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.7s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.937) total time=   0.7s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   0.8s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.7s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   0.8s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   0.7s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   0.8s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.934) total time=   0.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.9s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.936) total time=   2.8s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.933) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   4.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   3.9s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=   2.7s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.934) total time=   3.6s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.931) total time=   3.4s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   2.4s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   3.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.934) total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.916, test=0.917) total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.931) total time=  19.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  17.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.931) total time=  18.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.931) total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.929, test=0.930) total time=  19.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.930, test=0.930) total time=  18.5s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.931) total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=  18.7s\n",
      "[CV 1/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.937) total time=   4.0s\n",
      "[CV 2/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   2.6s\n",
      "[CV 3/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.0s\n",
      "[CV 4/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   2.2s\n",
      "[CV 5/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   2.2s\n",
      "[CV 6/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=   2.3s\n",
      "[CV 7/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.934) total time=   2.7s\n",
      "[CV 8/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   3.5s\n",
      "[CV 9/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   3.0s\n",
      "[CV 10/10] END lr__C=10, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.936) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.934) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.932) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.933) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.935) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.931) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.936) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.933) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   3.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.932) total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.933) total time=   3.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.933) total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.934) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=   3.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.930) total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.934) total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.930) total time=   4.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=   4.2s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   3.6s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.929) total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.935) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.930) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.930, test=0.932) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.932) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.932) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.930) total time=   0.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.934) total time=  12.6s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.930) total time=   8.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   5.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   5.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   5.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   5.4s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=  11.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   3.6s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.929) total time=   4.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.934) total time=  12.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.930) total time=   7.6s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   5.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.931) total time=   5.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   5.0s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   5.7s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.932) total time=  11.5s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   3.5s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.929) total time=   4.4s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.934) total time=   1.1s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.930) total time=   1.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   1.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   0.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   0.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   1.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   1.5s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.932) total time=   1.4s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.929) total time=   1.1s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.934) total time=   1.1s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.930) total time=   1.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   0.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   1.5s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   1.6s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.932) total time=   1.4s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   1.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.929) total time=   1.1s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.934) total time=   1.1s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.930) total time=   1.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   1.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   0.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.931) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   1.4s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   1.6s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.932) total time=   1.5s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   0.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.929) total time=   1.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.936) total time=   7.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=  16.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   6.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   8.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=  16.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  11.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   7.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   7.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time=   4.2s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   7.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.934) total time=   4.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.930) total time=   4.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   4.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   4.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   4.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   4.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   5.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.932) total time=   4.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   4.4s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.929) total time=   4.5s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.934) total time=   5.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.930) total time=   5.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   5.2s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   4.4s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   4.1s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   4.4s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   5.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.932) total time=   4.5s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   4.2s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.929) total time=   4.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.934) total time=   5.8s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.930) total time=   5.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   5.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   4.4s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.931) total time=   4.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   4.2s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   5.1s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.932) total time=   4.1s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=   4.1s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.929) total time=   4.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.934) total time=   6.1s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.930) total time=   5.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   2.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   4.6s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   3.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   4.0s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   4.4s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.932) total time=   6.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   3.1s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.929) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.934) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.930) total time=   3.9s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   3.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.931) total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.932) total time=   4.1s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   2.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 4.0, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.929) total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.936) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.931) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   0.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.936) total time=  13.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   8.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.932) total time=   5.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   5.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=   4.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.934) total time=   8.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  11.2s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.930) total time=   3.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   4.4s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.936) total time=  13.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   8.6s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.934) total time=   2.4s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.932) total time=   5.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   5.7s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=   5.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.934) total time=   8.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  11.1s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.930) total time=   3.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   4.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.936) total time=   7.9s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.933) total time=   6.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   4.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.932) total time=   3.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   3.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.933) total time=   4.0s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.934) total time=   4.0s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   7.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.930) total time=   2.6s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   6.6s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.936, test=0.936) total time=   7.4s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=  37.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   6.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   9.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  10.5s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.934) total time=   9.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   7.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time=   4.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=  10.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.936) total time=   5.1s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   4.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   2.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   3.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   3.3s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   3.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   3.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   5.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=   3.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.936, test=0.936) total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   3.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   2.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   3.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   3.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   3.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   3.6s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.936) total time=   1.1s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   1.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.932) total time=   1.0s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   1.1s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   0.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.934) total time=   1.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   1.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.930) total time=   1.1s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   1.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.936) total time=   1.1s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   1.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.932) total time=   1.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   0.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.934) total time=   1.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   1.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.930) total time=   1.1s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   1.1s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.936) total time=   1.1s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   1.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.935, test=0.932) total time=   1.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   1.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   0.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.934) total time=   1.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   1.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.930) total time=   1.1s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   1.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.936) total time=   3.4s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   4.6s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   5.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.932) total time=   3.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   3.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=   4.0s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.934) total time=   4.1s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   3.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.930) total time=   3.5s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   4.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.936) total time=   3.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   4.0s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   4.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.932) total time=   3.4s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   3.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=   4.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.934) total time=   3.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   3.7s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.930) total time=   3.5s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   4.1s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.936) total time=   3.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=   4.0s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   3.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.935, test=0.932) total time=   4.6s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   3.7s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=   4.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.934) total time=   4.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   3.7s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.930) total time=   3.4s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.936) total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=   4.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.935, test=0.932) total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.934) total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=   4.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.930) total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   3.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.936) total time=  12.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   7.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.2s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   5.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   5.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   4.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   5.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=  11.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=   3.7s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   4.1s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.936) total time=   5.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.933) total time=   4.6s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   2.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.932) total time=   3.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   3.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.933) total time=   3.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=   3.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   5.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.930) total time=   2.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.936) total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.933) total time=   4.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.931, test=0.933) total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.935, test=0.932) total time=   3.6s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.933) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   3.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.930) total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.930) total time=   3.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.936) total time=   0.9s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   1.0s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   1.0s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   1.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   1.1s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   1.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   1.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   1.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.936) total time=   0.9s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   1.0s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   1.0s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   1.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   1.1s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   1.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   1.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   1.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.936, test=0.936) total time=   1.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   1.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   1.0s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   0.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   1.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.931, test=0.933) total time=   1.1s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   1.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   1.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.930) total time=   1.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.936) total time=  12.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   7.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.2s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   5.0s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   5.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   4.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   5.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=  10.6s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=   3.4s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   4.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.936) total time=   4.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   4.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   3.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   3.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   4.8s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   4.2s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   5.4s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   3.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=   3.7s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   4.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.936) total time=   4.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   4.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   4.5s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   3.6s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   4.4s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   3.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   5.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   3.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=   3.6s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   4.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.936, test=0.936) total time=   3.9s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   4.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   4.1s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   3.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   4.4s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=   4.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.931, test=0.933) total time=   5.7s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=   4.4s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=   3.7s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.930) total time=   4.4s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.935, test=0.936) total time=   7.4s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.933) total time=   5.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.931, test=0.933) total time=   6.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   6.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   3.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.933) total time=   3.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.934) total time=   4.1s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   6.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.930) total time=   3.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.930) total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.936, test=0.936) total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   4.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.931, test=0.933) total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=   4.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.930) total time=   4.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 25\n",
      "n_resources: 119403\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=  21.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  18.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  16.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=  20.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=  18.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=  17.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=  19.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=  18.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  21.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  15.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=  21.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  17.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  16.5s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.931) total time=  20.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=  19.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=  17.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.933) total time=  18.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=  17.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  20.5s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  15.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   5.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   4.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   4.2s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   4.6s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   5.1s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   5.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   4.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   5.1s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   4.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   4.6s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   5.4s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   4.8s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   4.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   4.6s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   5.1s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   5.7s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   4.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   5.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   4.7s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   4.5s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   5.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   4.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   4.4s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.931) total time=   4.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   5.1s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   5.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.933) total time=   4.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   5.2s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   4.6s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   4.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=  22.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=   9.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  39.8s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.931) total time=  19.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.931) total time=  46.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time=  13.6s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.933) total time=  43.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  16.6s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  35.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  31.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=  13.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  15.6s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  13.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=  10.4s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  14.2s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  20.7s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=  30.5s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=  12.6s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  13.5s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  13.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=  14.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  16.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  13.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=   9.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  14.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  20.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=  30.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=  12.1s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  12.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  12.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.931) total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.933) total time=  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  12.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=  29.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  11.6s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  21.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.931) total time=  39.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time=  22.2s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time=  16.6s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.933) total time=  26.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.933) total time=  16.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  22.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.6, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  36.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=   9.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  10.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  10.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time=  18.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=   9.7s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time=  14.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  17.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.934) total time=  17.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.934) total time=  12.1s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.933) total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=  12.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  11.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  11.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.934) total time=  11.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.934) total time=  11.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.933) total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  12.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.934) total time=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=  12.6s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.931) total time=  12.6s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  10.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=   9.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time=   9.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.932) total time=  13.1s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  15.0s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  17.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.934) total time=  11.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.934) total time=  13.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.933) total time=   8.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=  13.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  15.9s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  13.7s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  10.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=  14.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  21.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  31.5s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  12.4s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.934) total time=  14.1s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=  13.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=  23.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  18.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  17.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=  14.9s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=  22.4s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  16.2s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  15.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.934) total time=  24.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.934) total time=  17.7s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=  15.1s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=  23.8s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  19.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  17.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=  15.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=  23.0s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  16.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  15.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.934) total time=  24.5s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.934) total time=  17.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=  14.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.931) total time=  23.4s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  20.0s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  16.2s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time=  15.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.932) total time=  22.4s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  16.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time=  15.9s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.934) total time=  23.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.934) total time=  17.7s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=  15.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   4.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   4.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   3.5s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   4.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   4.3s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   5.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   4.7s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.934) total time=   4.4s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.934) total time=   3.9s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   3.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.931) total time=  13.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=  14.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=  11.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=  12.7s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=  12.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=  17.1s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=  16.1s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.934) total time=  14.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.934) total time=  13.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.933) total time=  11.6s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   4.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   4.3s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   3.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   4.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   4.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   5.0s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   4.6s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.934) total time=   4.5s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.934) total time=   4.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   3.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.931) total time=   4.0s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   4.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   3.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.932) total time=   4.4s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.932, test=0.932) total time=   4.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.932) total time=   5.2s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.933) total time=   4.8s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.933, test=0.934) total time=   4.7s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.934) total time=   4.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=liblinear;, score=(train=0.934, test=0.933) total time=   4.0s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.931) total time=  13.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  16.1s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  14.3s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  10.3s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.932) total time=  14.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  20.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  31.0s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  12.0s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.934) total time=  13.8s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.931) total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=  11.0s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.932) total time=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.934) total time=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.934) total time=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.934) total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.933) total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.931) total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.931) total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.934) total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.933) total time=   2.4s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 9\n",
      "n_resources: 358209\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.935) total time=  42.4s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=  32.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=  29.1s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=  33.2s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.934) total time=  31.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.933) total time=  28.9s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.934) total time=  39.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=  25.1s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=  34.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=  38.2s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.935) total time=  42.6s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=   9.9s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.934) total time=   8.0s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  12.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  13.6s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=  10.4s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  39.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=   7.4s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  20.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  21.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.935) total time=  43.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  15.0s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.934) total time=   9.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  18.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  13.4s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=  10.4s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  39.3s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=   8.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  22.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  21.3s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.935) total time=  39.7s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  42.6s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.932, test=0.934) total time=  42.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.932) total time=  45.1s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  29.7s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.934, test=0.933) total time=  28.2s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.934) total time=  31.4s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  32.3s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  30.1s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time=  29.9s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.935) total time= 1.9min\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  50.6s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.934) total time= 1.5min\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time= 1.8min\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.934) total time= 1.5min\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=  57.8s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.934) total time= 2.1min\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time= 1.5min\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time= 2.3min\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=1000, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time= 1.2min\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.935) total time= 2.0min\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  51.2s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.934) total time= 1.5min\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time= 1.8min\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.934) total time= 1.5min\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=  56.3s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.934) total time= 2.0min\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time= 1.4min\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time= 2.2min\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time= 1.2min\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.935) total time= 1.9min\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time=  49.9s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.932, test=0.934) total time= 1.5min\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.932) total time= 1.7min\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.934) total time= 1.5min\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.934, test=0.933) total time=  57.2s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.934) total time= 2.0min\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time= 1.5min\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.932) total time= 2.2min\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=newton-cg;, score=(train=0.933, test=0.933) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.935) total time=  39.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  13.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.932, test=0.934) total time=   7.4s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.932) total time=  16.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  12.7s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.934, test=0.933) total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  39.6s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=   9.9s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  18.3s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  22.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.935) total time=  33.3s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=  33.5s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.932, test=0.934) total time=  28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.932) total time=  33.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.934) total time=  33.7s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.934, test=0.933) total time=  29.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.934) total time=  33.5s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=  25.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.932) total time=  34.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=lbfgs;, score=(train=0.933, test=0.933) total time=  33.5s\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 3\n",
      "n_resources: 1074627\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  42.2s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  43.4s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  47.9s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  29.5s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  24.9s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  27.7s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  51.2s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  24.8s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  30.6s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  23.8s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  46.5s\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.932) total time=  43.7s\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  35.6s\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  31.8s\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.934) total time=  26.5s\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  31.4s\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  47.7s\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  22.5s\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  27.0s\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=100, lr__penalty=l2, lr__solver=saga;, score=(train=0.933, test=0.933) total time=  30.7s\n",
      "[CV 1/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.934) total time= 2.0min\n",
      "[CV 2/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.932) total time= 2.8min\n",
      "[CV 3/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.934) total time= 2.0min\n",
      "[CV 4/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time= 1.9min\n",
      "[CV 5/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.934) total time= 1.9min\n",
      "[CV 6/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time= 1.8min\n",
      "[CV 7/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time= 2.5min\n",
      "[CV 8/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time= 2.2min\n",
      "[CV 9/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time= 1.8min\n",
      "[CV 10/10] END lr__C=100, lr__class_weight={0: 3.2, 1: 1.0}, lr__max_iter=500, lr__penalty=l2, lr__solver=sag;, score=(train=0.933, test=0.933) total time= 1.5min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingGridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=2, n_splits=5, random_state=42),\n",
       "                    estimator=Pipeline(steps=[('minmax', MinMaxScaler()),\n",
       "                                              ('lr', LogisticRegression())]),\n",
       "                    param_grid={'lr__C': [0.01, 0.1, 1, 10, 100],\n",
       "                                'lr__class_weight': [{0: 3.2, 1: 1.0},\n",
       "                                                     {0: 3.6, 1: 1.0},\n",
       "                                                     {0: 4.0, 1: 1.0}],\n",
       "                                'lr__max_iter': [100, 500, 1000],\n",
       "                                'lr__penalty': ['l2'],\n",
       "                                'lr__solver': ['newton-cg', 'lbfgs',\n",
       "                                               'liblinear', 'sag', 'saga']},\n",
       "                    scoring=make_scorer(fbeta_score, beta=0.5), verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26de85f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T15:43:22.541255Z",
     "iopub.status.busy": "2022-07-21T15:43:22.540415Z",
     "iopub.status.idle": "2022-07-21T15:43:22.611167Z",
     "shell.execute_reply": "2022-07-21T15:43:22.609964Z"
    },
    "papermill": {
     "duration": 0.335122,
     "end_time": "2022-07-21T15:43:22.614087",
     "exception": false,
     "start_time": "2022-07-21T15:43:22.278965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933255</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.933256</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>34.047845</td>\n",
       "      <td>8.343945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933257</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.933253</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>34.333146</td>\n",
       "      <td>9.906741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933226</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.933251</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>35.100641</td>\n",
       "      <td>6.234118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933222</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.933247</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>18.851585</td>\n",
       "      <td>11.069783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933257</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.933246</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>122.655254</td>\n",
       "      <td>20.965217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933223</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.933243</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>18.481840</td>\n",
       "      <td>12.078935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933224</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.933243</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>31.848016</td>\n",
       "      <td>2.694705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933222</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.933242</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>91.858908</td>\n",
       "      <td>26.003861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933222</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.933242</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>92.099382</td>\n",
       "      <td>26.119280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>{'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...</td>\n",
       "      <td>0.933222</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.933242</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>93.604841</td>\n",
       "      <td>26.416349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  mean_train_score  \\\n",
       "335  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933255   \n",
       "334  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933257   \n",
       "328  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933226   \n",
       "332  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933222   \n",
       "336  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933257   \n",
       "326  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933223   \n",
       "333  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933224   \n",
       "331  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933222   \n",
       "330  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933222   \n",
       "329  {'lr__C': 100, 'lr__class_weight': {0: 3.2, 1:...          0.933222   \n",
       "\n",
       "     std_train_score  mean_test_score  std_test_score  mean_fit_time  \\\n",
       "335         0.000107         0.933256        0.000357      34.047845   \n",
       "334         0.000104         0.933253        0.000356      34.333146   \n",
       "328         0.000489         0.933251        0.000905      35.100641   \n",
       "332         0.000503         0.933247        0.000917      18.851585   \n",
       "336         0.000111         0.933246        0.000362     122.655254   \n",
       "326         0.000500         0.933243        0.000916      18.481840   \n",
       "333         0.000498         0.933243        0.000922      31.848016   \n",
       "331         0.000502         0.933242        0.000912      91.858908   \n",
       "330         0.000502         0.933242        0.000912      92.099382   \n",
       "329         0.000502         0.933242        0.000912      93.604841   \n",
       "\n",
       "     std_fit_time  \n",
       "335      8.343945  \n",
       "334      9.906741  \n",
       "328      6.234118  \n",
       "332     11.069783  \n",
       "336     20.965217  \n",
       "326     12.078935  \n",
       "333      2.694705  \n",
       "331     26.003861  \n",
       "330     26.119280  \n",
       "329     26.416349  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_result_df(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c97de43a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T15:43:23.137274Z",
     "iopub.status.busy": "2022-07-21T15:43:23.136761Z",
     "iopub.status.idle": "2022-07-21T15:43:25.807298Z",
     "shell.execute_reply": "2022-07-21T15:43:25.806218Z"
    },
    "papermill": {
     "duration": 2.932774,
     "end_time": "2022-07-21T15:43:25.809982",
     "exception": false,
     "start_time": "2022-07-21T15:43:22.877208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=):\n",
      "Pipeline(steps=[('minmax', MinMaxScaler()),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=100, class_weight={0: 3.2, 1: 1.0},\n",
      "                                    solver='saga'))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.91      0.67     53638\n",
      "           1       0.97      0.81      0.88    215038\n",
      "\n",
      "    accuracy                           0.83    268676\n",
      "   macro avg       0.75      0.86      0.78    268676\n",
      "weighted avg       0.89      0.83      0.84    268676\n",
      "\n",
      "[[ 48640   4998]\n",
      " [ 41864 173174]]\n",
      "f0.5_score= 0.9333251412593806\n",
      "pr_auc_score= 0.9815797945640102\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmax', MinMaxScaler()),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=100, class_weight={0: 3.2, 1: 1.0},\n",
       "                                    solver='saga'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_best_model_result(search, 'MinMaxScaler + Tuning class weight + Tuning Logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54a2bbf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T15:43:26.329777Z",
     "iopub.status.busy": "2022-07-21T15:43:26.329013Z",
     "iopub.status.idle": "2022-07-21T15:43:27.424629Z",
     "shell.execute_reply": "2022-07-21T15:43:27.423482Z"
    },
    "papermill": {
     "duration": 1.357957,
     "end_time": "2022-07-21T15:43:27.427392",
     "exception": false,
     "start_time": "2022-07-21T15:43:26.069435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2520x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_search_results(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "529a180a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T15:43:27.952145Z",
     "iopub.status.busy": "2022-07-21T15:43:27.951726Z",
     "iopub.status.idle": "2022-07-21T15:51:14.842196Z",
     "shell.execute_reply": "2022-07-21T15:51:14.840771Z"
    },
    "papermill": {
     "duration": 467.422462,
     "end_time": "2022-07-21T15:51:15.109563",
     "exception": false,
     "start_time": "2022-07-21T15:43:27.687101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(search.best_estimator_, 'MinMaxScaler + Tuning class weight + Tuning Logistic', X_train, y_train, cv=cv, n_jobs=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc7ebf",
   "metadata": {
    "papermill": {
     "duration": 0.26292,
     "end_time": "2022-07-21T15:51:15.725869",
     "exception": false,
     "start_time": "2022-07-21T15:51:15.462949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14224.185429,
   "end_time": "2022-07-21T15:51:18.652548",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-21T11:54:14.467119",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
